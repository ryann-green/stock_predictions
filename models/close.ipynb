{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e862ba5-1a18-437d-a215-4abe008c360e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas_ta'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_37372\\1895724117.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas_ta\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0myfinance\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0myf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas_ta'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd66cfe5-1744-4228-ba50-5128577ab70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current date in YYYY-MM-DD format\n",
    "current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "# Define the path to the new folder within the home directory\n",
    "home_directory = os.path.expanduser('~/Code/stock_predictions/10_day_ahead_close/stock_performance')\n",
    "new_folder_path = os.path.join(home_directory, current_date)\n",
    "\n",
    "# Create the folder if it doesn't already exist\n",
    "if not os.path.exists(new_folder_path):\n",
    "    os.makedirs(new_folder_path)\n",
    "    print(f\"Folder created: {new_folder_path}\")\n",
    "else:\n",
    "    print(f\"Folder already exists: {new_folder_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae42563-099d-4c0f-8e8e-a4684e7629b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching historical data for GOOG\n",
    "tickers = ['AAPL'\n",
    "           ,'GOOG'\n",
    "           ,'DRI'\n",
    "           ,'PAYX'\n",
    "           ,'SBUX'\n",
    "           ,'VAC'\n",
    "           ,'KR'\n",
    "           ,'CMI'\n",
    "           ,'MA'\n",
    "           ,'PG'\n",
    "           ,'HPE'\n",
    "           ,'CAT'\n",
    "           ,'AMZN'\n",
    "           ,'KO'\n",
    "           ,'CSCO'\n",
    "           ,'JCI'\n",
    "           ,'BFIN'\n",
    "           ,'XLK'\n",
    "           ,'XLI'\n",
    "           ,'XLY'\n",
    "           ,'XLF'\n",
    "           ,'XLRE'\n",
    "           ,'XLU'\n",
    "           ,'XLB'\n",
    "           ,'XLP'\n",
    "           ,'XLV'\n",
    "           ,'XLE'\n",
    "           ,'XLC'\n",
    "           ,'NVDA'\n",
    "           ,'EA'\n",
    "           ,'ADBE'\n",
    "           ,'AFG'\n",
    "           ,'ARCC'\n",
    "           ,'ADP'\n",
    "           ,'AVNT'\n",
    "           ,'AXS'\n",
    "           ,'BAX'\n",
    "           ,'CPB'\n",
    "           ,'CNI'\n",
    "           ,'KO'\n",
    "           ,'CTBI'\n",
    "           ,'EMR'\n",
    "           ,'PRU'\n",
    "           ,'QSR'\n",
    "           ,'SUN'\n",
    "           ,'TRN'\n",
    "           ,'UNP'\n",
    "           ,'WSO'\n",
    "           ,'NSC'\n",
    "           ,'SYY'\n",
    "           ,'DDOG'\n",
    "           ,'PLTR'\n",
    "           ,'AMD'\n",
    "           ]\n",
    "# tickers = ['AAPL','GOOG','DRI','PAYX','SBUX','VAC','KR','CMI']\n",
    "end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "start_date = (datetime.now() - timedelta(days=125 * 1)).strftime('%Y-%m-%d')\n",
    "days_ahead=10\n",
    "\n",
    "prediction_results=[]\n",
    "detailed_results=[]\n",
    "\n",
    "def get_initial_df (ticker):\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    # Calculate leading technical indicators\n",
    "    data['ALMA'] = ta.alma(data['Close'])\n",
    "    stoch_rsi = ta.stochrsi(data['Close'])\n",
    "    data['Stochastic_RSI'] = stoch_rsi['STOCHRSIk_14_14_3_3']\n",
    "    data['Williams_%R'] = ta.willr(data['High'], data['Low'], data['Close'])\n",
    "    data['ROC'] = ta.roc(data['Close'])\n",
    "    data['low_close_spread']= (data['Low']-data['Close'])/data['Low']\n",
    "    data['stop_loss']=data['low_close_spread'].min()\n",
    "    \n",
    "    return data\n",
    "\n",
    "def shift_ahead (data,days_ahead):\n",
    "    \n",
    "    for i in range(1, days_ahead):\n",
    "        data[f'{i}_Day Close Change'] = (data['Close'] - data['Close'].shift(i))/data['Close'].shift(i)\n",
    "        data[f'{i}_Day Volume Change'] = data['Volume'] - data['Volume'].shift(i)\n",
    "        \n",
    "    # Drop any rows with NaN values generated by indicator calculations\n",
    "    data.dropna(inplace=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def generate_lead_features (data,days_ahead):\n",
    "    \n",
    "        # # Generate lead features for the past 30 days\n",
    "    # Shift (i) positive means that the data from the previous \"i\" day prior to the current row will be reflected in the lead_i column \n",
    "    lead_features = []\n",
    "\n",
    "    for i in range(1, days_ahead):\n",
    "        \n",
    "        cols=['Close', 'ALMA', 'Stochastic_RSI', 'Williams_%R', 'ROC']\n",
    "        \n",
    "        # add each day close and volume change as additional columns to evaluate for features\n",
    "        for n in range(1, days_ahead):\n",
    "            cols.append(f'{n}_Day Close Change')\n",
    "            cols.append(f'{n}_Day Volume Change')\n",
    "        \n",
    "        leads = data[cols].shift(i)\n",
    "        leads.columns = [f'{col}_lead_{i}' for col in leads.columns]\n",
    "        lead_features.append(leads)\n",
    "        \n",
    "        return lead_features\n",
    "\n",
    "def prep_train_test_data(data,feature_cols,target_col):\n",
    "        # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data[feature_cols], data[target_col], test_size=0.2, random_state=42)\n",
    "\n",
    "    # # # Feature selection using SelectKBest\n",
    "    k_best_features = SelectKBest(f_regression, k=10)\n",
    "    \n",
    "   \n",
    "    X_train_selected = k_best_features.fit_transform(X_train, y_train)\n",
    "    X_test_selected = k_best_features.transform(X_test)\n",
    "\n",
    "    # # # Get the selected feature names\n",
    "    selected_feature_names = [feature_cols[i] for i in k_best_features.get_support(indices=True)]\n",
    "    print(selected_feature_names)\n",
    "\n",
    "    # # # Convert X_train_selected and X_test_selected back to DataFrames for easier manipulation\n",
    "    X_train_selected_df = pd.DataFrame(X_train_selected, index=X_train.index, columns=selected_feature_names).sort_index(ascending=True)\n",
    "    # print(X_train_selected_df)\n",
    "    X_test_selected_df = pd.DataFrame(X_test_selected, index=X_test.index, columns=selected_feature_names).sort_index(ascending=True)\n",
    "    \n",
    "    return X_train_selected_df,X_test_selected_df,y_train,y_test,selected_feature_names\n",
    "\n",
    "def train_model (model_items,days_ahead,X_train_selected_df,X_test_selected_df,y_train,y_test,predictions_df):\n",
    "    # # # Train and evaluate each model\n",
    "    results = {}\n",
    "    \n",
    "    for model_name, model in model_items:\n",
    "    \n",
    "        model.fit(X_train_selected_df, y_train)\n",
    "        predictions = model.predict(X_test_selected_df)\n",
    "        \n",
    "    #     # Create a DataFrame for predictions with the same index as the training set\n",
    "        predictions_train = pd.DataFrame(model.predict(X_train_selected_df), index=X_train_selected_df.index, columns=[f'{model_name}_Predicted_Close_{days_ahead}d_ahead'])\n",
    "        # print(predictions_train)\n",
    "\n",
    "    #     # Merge the predictions with the predictions_df DataFrame\n",
    "        predictions_df = predictions_df.merge(predictions_train, left_index=True,right_index=True, how='left')\n",
    "        \n",
    "        mse = mean_squared_error(y_test, predictions)\n",
    "        rmse = np.sqrt(mse)\n",
    "        results[model_name] = rmse\n",
    "        print(f'{model_name} RMSE: {rmse}')\n",
    "        \n",
    "    return results, predictions_df\n",
    "\n",
    "completed=[]\n",
    "     \n",
    "for ticker in tickers:\n",
    "    \n",
    "    if ticker not in completed:\n",
    "        completed.append(ticker)\n",
    "    \n",
    "        print(ticker)\n",
    "        \n",
    "        data= shift_ahead (\n",
    "                get_initial_df(ticker)\n",
    "                ,days_ahead\n",
    "                )\n",
    "\n",
    "        lead_features_df=pd.concat(generate_lead_features(data,days_ahead), axis=1)\n",
    "\n",
    "        # print(lead_features_df)\n",
    "        data = pd.concat([data, lead_features_df], axis=1)\n",
    "        \n",
    "        data.dropna(inplace=True)\n",
    "        \n",
    "        # print(data)\n",
    "\n",
    "        # Make a copy of the dataset before adding the column needed for a target for the closing price 30 days in the future for training the model\n",
    "        train_data=data.iloc[:-1]\n",
    "        full=data.copy()\n",
    "        # print(train_data)\n",
    "\n",
    "        # # Create target column by shifting the close price by -target days (closing price from target days in the future)\n",
    "        data[f'Close_{days_ahead}d_ahead'] = data['Close'].shift(-days_ahead)\n",
    "\n",
    "        # print(data)\n",
    "        \n",
    "        # this will get rid of the data form the last 30 trading days to train the model\n",
    "        data.dropna(inplace=True)\n",
    "\n",
    "        # identify target column\n",
    "        target_col = f'Close_{days_ahead}d_ahead'\n",
    "        \n",
    "        # Define feature columns (past target days of technical indicators)\n",
    "        feature_cols = lead_features_df.columns.tolist()\n",
    "        \n",
    "        # print(feature_cols)\n",
    "        \n",
    "        # get the main columns for the current day that aren't shifted. These need to be included to gauge the latest days information to include in the model\n",
    "        main_cols=['Open','High','Low','Close','Adj Close','Volume','ALMA','Stochastic_RSI','Williams_%R','ROC']\n",
    "        \n",
    "        for col in main_cols:\n",
    "            feature_cols.append(col)\n",
    "        \n",
    "        X_train_selected_df,X_test_selected_df,y_train,y_test,selected_feature_names =prep_train_test_data(data,feature_cols,target_col)\n",
    "\n",
    "        # # # List of models to train\n",
    "        models = {\n",
    "            'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "            'LinearRegression': LinearRegression(),\n",
    "            'XGBoost': XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "        }\n",
    "        \n",
    "        # # # Evaluate the model's predicted values vs the actual values for past predictions\n",
    "        predictions_df = data.copy()\n",
    "        results,predictions_df=train_model(models.items(),days_ahead,X_train_selected_df,X_test_selected_df,y_train,y_test,predictions_df)\n",
    "            \n",
    "        # # Select the best model\n",
    "        best_model_name = min(results, key=results.get)\n",
    "        best_model = models[best_model_name]\n",
    "\n",
    "        print(f'\\nBest model: {best_model_name} with RMSE: {results[best_model_name]}')\n",
    "        \n",
    "        evaluation_df=predictions_df[['Close',target_col, f'{best_model_name}_Predicted_Close_{days_ahead}d_ahead']]\n",
    "\n",
    "        # # Drop rows with NaN values before calculating RMSE\n",
    "        evaluation_df = evaluation_df.dropna()\n",
    "        evaluation_df['Actual_vs_Predicted_Diff %'] = (evaluation_df[target_col] - evaluation_df[f'{best_model_name}_Predicted_Close_{days_ahead}d_ahead'])/evaluation_df[f'{best_model_name}_Predicted_Close_{days_ahead}d_ahead']\n",
    "        evaluation_rmse = np.sqrt(mean_squared_error(evaluation_df[target_col], evaluation_df[f'{best_model_name}_Predicted_Close_{days_ahead}d_ahead']))\n",
    "        print(f'\\nEvaluation RMSE for past predictions: {evaluation_rmse}')\n",
    "\n",
    "        # Adding columns to indicate if the predicted close is higher and if the actual future close is higher\n",
    "        evaluation_df['Predicted_Higher'] = evaluation_df[f'{best_model_name}_Predicted_Close_{days_ahead}d_ahead'] > evaluation_df['Close']\n",
    "        evaluation_df['Actual_Higher'] = evaluation_df[target_col] > evaluation_df['Close']\n",
    "\n",
    "        # Adding column to indicate if the model's prediction was correct\n",
    "        evaluation_df['Prediction_Correct'] = evaluation_df['Predicted_Higher'] == evaluation_df['Actual_Higher']\n",
    "        \n",
    "        evaluation_df['ticker']=ticker\n",
    "\n",
    "        # print(evaluation_df)\n",
    "\n",
    "        # Aggregating the data\n",
    "        total_predictions = len(evaluation_df)\n",
    "        total_correct_predictions = evaluation_df['Prediction_Correct'].sum()\n",
    "        predicted_higher_correct = evaluation_df[evaluation_df['Predicted_Higher'] & evaluation_df['Prediction_Correct']].shape[0]\n",
    "        total_predicted_higher = evaluation_df['Predicted_Higher'].sum()\n",
    "        average_act_vs_pred_diff=evaluation_df['Actual_vs_Predicted_Diff %'].mean()\n",
    "        median_act_vs_pred_diff=evaluation_df['Actual_vs_Predicted_Diff %'].median()\n",
    "\n",
    "        # Calculating success rates\n",
    "        overall_success_rate = total_correct_predictions / total_predictions\n",
    "        predicted_higher_success_rate = predicted_higher_correct / total_predicted_higher if total_predicted_higher != 0 else 0\n",
    "\n",
    "        pred_results={}\n",
    "        pred_results['ticker']=ticker\n",
    "        pred_results['total_predictions']=total_predictions\n",
    "        pred_results['total_correct_predicions']=total_correct_predictions\n",
    "        pred_results['overall_success_rate']=overall_success_rate\n",
    "        pred_results['predicted_higher_correct']=predicted_higher_correct\n",
    "        pred_results['total_predicted_higher']=total_predicted_higher\n",
    "        pred_results['predicted_higher_success_rate']=predicted_higher_success_rate\n",
    "        # pred_results['average_act_vs_pred_diff']=average_act_vs_pred_diff\n",
    "        # pred_results['median_act_vs_pred_diff']=median_act_vs_pred_diff\n",
    "        pred_results['adj_sell_vs_pred_pct']=(average_act_vs_pred_diff+median_act_vs_pred_diff)/2\n",
    "        \n",
    "        last_row = full.iloc[-1:]\n",
    "        pred_results['latest_close']=last_row['Close'][0]\n",
    "\n",
    "        # Extract the features used for model training from the last row\n",
    "        # Ensure that `selected_feature_names` are the features selected during training\n",
    "        latest_features = last_row[selected_feature_names].values.reshape(1, -1)\n",
    "\n",
    "        # Step 2: Use the best model to predict the closing price 10 days in advance\n",
    "        if ticker =='XLU':\n",
    "            print(latest_features)\n",
    "        predicted_price_10_days_ahead = best_model.predict(latest_features)[0]\n",
    "\n",
    "        # Step 3: Output the prediction\n",
    "        pred_results['last_date_for_prediction']=last_row.index[0]\n",
    "        pred_results['prediction_price']=predicted_price_10_days_ahead\n",
    "        \n",
    "        adj_prediction_price=predicted_price_10_days_ahead*(1+(average_act_vs_pred_diff+median_act_vs_pred_diff)/2)\n",
    "        pred_results['adj_prediction_price']=adj_prediction_price\n",
    "        pred_results['adj_prediction_higher']=adj_prediction_price>last_row['Close'][0]\n",
    "        pred_results['stop_loss ']=full['stop_loss'].min()\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Output the results\n",
    "        print(f\"Total Predictions: {total_predictions}\")\n",
    "        print(f\"Total Correct Predictions: {total_correct_predictions}\")\n",
    "        print(f\"Overall Success Rate: {overall_success_rate:.2%}\")\n",
    "        print(f\"Predicted Higher Correct: {predicted_higher_correct}\")\n",
    "        print(f\"Total Predicted Higher: {total_predicted_higher}\")\n",
    "        print(f\"Predicted Higher Success Rate: {predicted_higher_success_rate:.2%}\")\n",
    "        print(f\"Predicted closing price 10 days ahead of {last_row.index[0]}: {predicted_price_10_days_ahead}\")\n",
    "        print(f\"Adjusted Predicted closing price 10 days ahead of {last_row.index[0]}: {adj_prediction_price}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        prediction_results.append(pred_results)\n",
    "        \n",
    "        new_folder_path = os.path.join(home_directory,current_date ,'tickers')\n",
    "\n",
    "        # Create the folder if it doesn't already exist\n",
    "        if not os.path.exists(new_folder_path):\n",
    "            os.makedirs(new_folder_path)\n",
    "            print(f\"Folder created: {new_folder_path}\")\n",
    "        else:\n",
    "            pass\n",
    "            # print(f\"Folder already exists: {new_folder_path}\")\n",
    "\n",
    "        # Saving the dataframe for future reference\n",
    "        evaluation_df.to_csv(f'{new_folder_path}/{ticker}_model_performance_analysis.csv')\n",
    "        full.reset_index()[['Date','Open','High','Low','Close','Adj Close','Volume','stop_loss']].to_csv(f'{new_folder_path}/{ticker}_data.csv')\n",
    "        \n",
    "        detailed_results.append(evaluation_df)\n",
    "        \n",
    "        print(full.iloc[-1:])\n",
    "\n",
    "all_results=pd.DataFrame(prediction_results).sort_values('predicted_higher_success_rate', ascending=False)\n",
    "all_results.to_csv(f'{new_folder_path}/all_results.csv')\n",
    "all_results.to_csv('~/Code/stock_predictions/dash/latest_results.csv')\n",
    "pd.concat(detailed_results).to_csv(f'{new_folder_path}/detailed_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
